{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tXC4A3N5y7h6"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gbIslKLZ0MCc",
    "outputId": "422659a6-fab0-4763-8ef8-22f6489f8737"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bert-for-tf2 in /usr/local/lib/python3.7/dist-packages (0.14.9)\n",
      "Requirement already satisfied: params-flow>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from bert-for-tf2) (0.8.2)\n",
      "Requirement already satisfied: py-params>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from bert-for-tf2) (0.10.2)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from params-flow>=0.8.0->bert-for-tf2) (1.19.5)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from params-flow>=0.8.0->bert-for-tf2) (4.62.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install bert-for-tf2\n",
    "# !pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YN42JNkC0WWe"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MO8t7S8D0bvf"
   },
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HiutB0ub0e9n"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "import bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3RyaS89_04CP",
    "outputId": "0b670de7-e24c-43ba-85b1-835911b5adc8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IMPUD3GVnVgy"
   },
   "outputs": [],
   "source": [
    "data = pd.read_excel('tweet_for_help.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "0ELMpCubnYdJ",
    "outputId": "63ff7cd2-383d-4842-e9cb-94685748f4ea"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>tweet</th>\n",
       "      <th>help</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Our NGO partner @manuvikasa is identifying tho...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>This man from AP, is stuck in Assam for a mont...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Respected chief minister\\nI am Anoop Tiwari fr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>@Corp190_Sheetal hello mam I want food materia...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>we distributed 4000 food kits \\nfrom RSS Seva ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                              tweet  help\n",
       "0      0  Our NGO partner @manuvikasa is identifying tho...     0\n",
       "1      1  This man from AP, is stuck in Assam for a mont...     1\n",
       "2      2  Respected chief minister\\nI am Anoop Tiwari fr...     1\n",
       "3      3  @Corp190_Sheetal hello mam I want food materia...     1\n",
       "4      4  we distributed 4000 food kits \\nfrom RSS Seva ...     0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "-1m-dFyD1Hd9",
    "outputId": "08fd57a6-1f52-43e2-84de-321d6569d27e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>help</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Our NGO partner @manuvikasa is identifying tho...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This man from AP, is stuck in Assam for a mont...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Respected chief minister\\nI am Anoop Tiwari fr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@Corp190_Sheetal hello mam I want food materia...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>we distributed 4000 food kits \\nfrom RSS Seva ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  help\n",
       "0  Our NGO partner @manuvikasa is identifying tho...     0\n",
       "1  This man from AP, is stuck in Assam for a mont...     1\n",
       "2  Respected chief minister\\nI am Anoop Tiwari fr...     1\n",
       "3  @Corp190_Sheetal hello mam I want food materia...     1\n",
       "4  we distributed 4000 food kits \\nfrom RSS Seva ...     0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data[['tweet','help']]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "id": "paq9Ko5cnd3l",
    "outputId": "4f4641d5-43e4-4224-a942-0eefb7d8ad3a"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Our NGO partner @manuvikasa is identifying those in severe need of help in Karnataka through GPS. They are also distributing food kits to these families, and saving them from destitution amid the ongoing #crisis. To support their initiative, please visit https://bit.ly/2xpPKMo\\xa0https://twitter.com/EdelGive/status/1254697953878585345\\xa0â€¦'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['tweet'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6gABXGVzomlk",
    "outputId": "70955bb3-db2d-4220-dc96-7d74ec9e07bd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3911\n",
       "1    1089\n",
       "Name: help, dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.help.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z1jA3tT72EnT"
   },
   "source": [
    "# Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9xRHsL452Ct6"
   },
   "outputs": [],
   "source": [
    "def clean_tweet(tweet):\n",
    "    try:\n",
    "        # tweet = BeautifulSoup(tweet, \"lxml\").get_text()\n",
    "        # Removing the @\n",
    "        tweet = re.sub(r\"@[A-Za-z0-9]+\", ' ', tweet)\n",
    "        # Removing the URL links\n",
    "        tweet = re.sub(r\"https?://[A-Za-z0-9./]+\", ' ', tweet)\n",
    "        # Keeping only letters\n",
    "        tweet = re.sub(r\"[^a-zA-Z.!?']\", ' ', tweet)\n",
    "        # Removing additional whitespaces\n",
    "        tweet = re.sub(r\" +\", ' ', tweet)\n",
    "        tweet = re.sub(r\"\\.+\", '.', tweet)\n",
    "        return tweet\n",
    "    except:\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MUwwYGUp3TI5"
   },
   "outputs": [],
   "source": [
    "data_clean = [clean_tweet(tweet) for tweet in data.tweet]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "id": "V6csR50rxkX1",
    "outputId": "7e35a9d8-97fa-4df4-c9e2-709a4d7ea5a7"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Our NGO partner is identifying those in severe need of help in Karnataka through GPS. They are also distributing food kits to these families and saving them from destitution amid the ongoing crisis. To support their initiative please visit '"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_clean[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nW1vwDrc3a0p"
   },
   "outputs": [],
   "source": [
    "data_labels = data.help.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ztA6DoHmzmWd",
    "outputId": "c7b17d2e-0904-4f8a-ef22-904384a52b4b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fkb8Swr638Pu"
   },
   "source": [
    "# Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2ATCeVFK356k"
   },
   "outputs": [],
   "source": [
    "\n",
    "FullTokenizer = bert.bert_tokenization.FullTokenizer\n",
    "bert_layer = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/1\",\n",
    "                            trainable=False)\n",
    "vocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
    "do_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n",
    "tokenizer = FullTokenizer(vocab_file, do_lower_case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EATTyVMwNckk",
    "outputId": "177423f3-39ae-4b9c-81db-582979060d09"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['my', 'name', 'is', 'narayan', '##a']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize(\"My name is Narayana\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UEjq_1DuyxiN",
    "outputId": "2d375f79-4586-4da2-a48a-b4c97a1875aa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'am', 'su', '##hai', '##l']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize(\"I am suhail\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RmjMxhyTNjcm"
   },
   "outputs": [],
   "source": [
    "def encode_sentence(sentence):\n",
    "  return [\"[CLS]\"] + tokenizer.tokenize(sentence) + [\"[SEP]\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "73xn5QjdNxad",
    "outputId": "5d8accbc-40ae-421a-83cc-fd1f5cf1399c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]', 'hey', 'i', 'am', 'gala', '##b', '[SEP]']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode_sentence('Hey I am Galab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w_A2ga9q5e3L"
   },
   "outputs": [],
   "source": [
    "data_inputs = [encode_sentence(sentence) for sentence in data_clean]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S_ZKkB_b71AK",
    "outputId": "7252678c-3146-4e60-d57a-a34dee040ef5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]',\n",
       " 'our',\n",
       " 'ngo',\n",
       " 'partner',\n",
       " 'is',\n",
       " 'identifying',\n",
       " 'those',\n",
       " 'in',\n",
       " 'severe',\n",
       " 'need',\n",
       " 'of',\n",
       " 'help',\n",
       " 'in',\n",
       " 'karnataka',\n",
       " 'through',\n",
       " 'gps',\n",
       " '.',\n",
       " 'they',\n",
       " 'are',\n",
       " 'also',\n",
       " 'distributing',\n",
       " 'food',\n",
       " 'kits',\n",
       " 'to',\n",
       " 'these',\n",
       " 'families',\n",
       " 'and',\n",
       " 'saving',\n",
       " 'them',\n",
       " 'from',\n",
       " 'des',\n",
       " '##ti',\n",
       " '##tu',\n",
       " '##tion',\n",
       " 'amid',\n",
       " 'the',\n",
       " 'ongoing',\n",
       " 'crisis',\n",
       " '.',\n",
       " 'to',\n",
       " 'support',\n",
       " 'their',\n",
       " 'initiative',\n",
       " 'please',\n",
       " 'visit',\n",
       " '[SEP]']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_inputs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_PKHJT_H7ZBm"
   },
   "source": [
    "# Dataset creating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VcAmnsbaOf8Z"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_ids(tokens):\n",
    "  return tokenizer.convert_tokens_to_ids(tokens)\n",
    "\n",
    "def get_mask(tokens):\n",
    "  return np.char.not_equal( tokens, \"[PAD]\" ).astype(int)\n",
    "\n",
    "def get_segments(tokens):\n",
    "  seg_ids = []\n",
    "  current_seg_id = 0\n",
    "  for tok in tokens:\n",
    "    seg_ids.append(current_seg_id)\n",
    "    if tok == \"[SEP]\":\n",
    "      current_seg_id = 1 - current_seg_id\n",
    "  return seg_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 132
    },
    "id": "2WQ9RQgwxFIh",
    "outputId": "09acf6fc-455a-4156-b634-80a8fb576a68"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[CLS]</td>\n",
       "      <td>our</td>\n",
       "      <td>ngo</td>\n",
       "      <td>partner</td>\n",
       "      <td>is</td>\n",
       "      <td>identifying</td>\n",
       "      <td>those</td>\n",
       "      <td>in</td>\n",
       "      <td>severe</td>\n",
       "      <td>need</td>\n",
       "      <td>of</td>\n",
       "      <td>help</td>\n",
       "      <td>in</td>\n",
       "      <td>karnataka</td>\n",
       "      <td>through</td>\n",
       "      <td>gps</td>\n",
       "      <td>.</td>\n",
       "      <td>they</td>\n",
       "      <td>are</td>\n",
       "      <td>also</td>\n",
       "      <td>distributing</td>\n",
       "      <td>food</td>\n",
       "      <td>kits</td>\n",
       "      <td>to</td>\n",
       "      <td>these</td>\n",
       "      <td>families</td>\n",
       "      <td>and</td>\n",
       "      <td>saving</td>\n",
       "      <td>them</td>\n",
       "      <td>from</td>\n",
       "      <td>des</td>\n",
       "      <td>##ti</td>\n",
       "      <td>##tu</td>\n",
       "      <td>##tion</td>\n",
       "      <td>amid</td>\n",
       "      <td>the</td>\n",
       "      <td>ongoing</td>\n",
       "      <td>crisis</td>\n",
       "      <td>.</td>\n",
       "      <td>to</td>\n",
       "      <td>support</td>\n",
       "      <td>their</td>\n",
       "      <td>initiative</td>\n",
       "      <td>please</td>\n",
       "      <td>visit</td>\n",
       "      <td>[SEP]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101</td>\n",
       "      <td>2256</td>\n",
       "      <td>17895</td>\n",
       "      <td>4256</td>\n",
       "      <td>2003</td>\n",
       "      <td>12151</td>\n",
       "      <td>2216</td>\n",
       "      <td>1999</td>\n",
       "      <td>5729</td>\n",
       "      <td>2342</td>\n",
       "      <td>1997</td>\n",
       "      <td>2393</td>\n",
       "      <td>1999</td>\n",
       "      <td>12092</td>\n",
       "      <td>2083</td>\n",
       "      <td>14658</td>\n",
       "      <td>1012</td>\n",
       "      <td>2027</td>\n",
       "      <td>2024</td>\n",
       "      <td>2036</td>\n",
       "      <td>20083</td>\n",
       "      <td>2833</td>\n",
       "      <td>18628</td>\n",
       "      <td>2000</td>\n",
       "      <td>2122</td>\n",
       "      <td>2945</td>\n",
       "      <td>1998</td>\n",
       "      <td>7494</td>\n",
       "      <td>2068</td>\n",
       "      <td>2013</td>\n",
       "      <td>4078</td>\n",
       "      <td>3775</td>\n",
       "      <td>8525</td>\n",
       "      <td>3508</td>\n",
       "      <td>13463</td>\n",
       "      <td>1996</td>\n",
       "      <td>7552</td>\n",
       "      <td>5325</td>\n",
       "      <td>1012</td>\n",
       "      <td>2000</td>\n",
       "      <td>2490</td>\n",
       "      <td>2037</td>\n",
       "      <td>6349</td>\n",
       "      <td>3531</td>\n",
       "      <td>3942</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0     1      2        3     4   ...     41          42      43     44     45\n",
       "0  [CLS]   our    ngo  partner    is  ...  their  initiative  please  visit  [SEP]\n",
       "1    101  2256  17895     4256  2003  ...   2037        6349    3531   3942    102\n",
       "\n",
       "[2 rows x 46 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame([data_inputs[0],get_ids(data_inputs[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YniMv15C9Vdp",
    "outputId": "8329b552-f44f-4b74-c8b0-b86627837ac9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'hey', 'i', 'am', 'gala', '##b', '[SEP]', '[PAD]', '[PAD]', '[PAD]']\n",
      "[1 1 1 1 1 1 1 0 0 0]\n",
      "[101, 4931, 1045, 2572, 16122, 2497, 102, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "out = encode_sentence('Hey I am Galab')\n",
    "out.append('[PAD]')\n",
    "out.append('[PAD]')\n",
    "out.append('[PAD]')\n",
    "print (out)\n",
    "print (get_mask(out))\n",
    "print (get_ids(out))\n",
    "print (get_segments(out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eUgYEczdQJi7"
   },
   "outputs": [],
   "source": [
    "data_with_len = [[sent, data_labels[i], len(sent)] for i,sent in enumerate(data_inputs) ]\n",
    "random.shuffle(data_with_len)\n",
    "data_with_len.sort(key= lambda x: x[2] )\n",
    "sorted_all = [([get_ids(sent_lab[0]),\n",
    "                get_mask(sent_lab[0]),\n",
    "                get_segments(sent_lab[0])],\n",
    "                sent_lab[1]) for sent_lab in data_with_len if sent_lab[2]>7 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "flhSlzYeDQ1X",
    "outputId": "ee5dcaa8-d8ef-47c1-d5e2-c957746773a7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "130"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sorted_all[len(sorted_all) -1][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TcMvnseN9rXg"
   },
   "outputs": [],
   "source": [
    "\n",
    "all_dataset = tf.data.Dataset.from_generator(lambda: sorted_all,\n",
    "                                             output_types=(tf.int32, tf.int32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v6szNyDB9Ldt",
    "outputId": "89e75e28-1bb2-48b8-df53-59af09c73a5f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(3, 8), dtype=int32, numpy=\n",
       " array([[  101,  2214,  2739,  1012, 21887,  2165,  2058,   102],\n",
       "        [    1,     1,     1,     1,     1,     1,     1,     1],\n",
       "        [    0,     0,     0,     0,     0,     0,     0,     0]],\n",
       "       dtype=int32)>, <tf.Tensor: shape=(), dtype=int32, numpy=0>)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(all_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pkI0TpTT-Bnf",
    "outputId": "cd91d335-e8bb-4bf3-c945-5ecbe8496f6d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total batches = 156\n",
      "2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(32, 3, 15), dtype=int32, numpy=\n",
       " array([[[  101,  2057,  2031, ...,   102,     0,     0],\n",
       "         [    1,     1,     1, ...,     1,     0,     0],\n",
       "         [    0,     0,     0, ...,     0,     0,     0]],\n",
       " \n",
       "        [[  101,  2054,  2023, ...,   102,     0,     0],\n",
       "         [    1,     1,     1, ...,     1,     0,     0],\n",
       "         [    0,     0,     0, ...,     0,     0,     0]],\n",
       " \n",
       "        [[  101, 22889,  2213, ...,   102,     0,     0],\n",
       "         [    1,     1,     1, ...,     1,     0,     0],\n",
       "         [    0,     0,     0, ...,     0,     0,     0]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[  101,  1045,  2064, ..., 26419,  2232,   102],\n",
       "         [    1,     1,     1, ...,     1,     1,     1],\n",
       "         [    0,     0,     0, ...,     0,     0,     0]],\n",
       " \n",
       "        [[  101, 21887,  2005, ...,  1029,  1029,   102],\n",
       "         [    1,     1,     1, ...,     1,     1,     1],\n",
       "         [    0,     0,     0, ...,     0,     0,     0]],\n",
       " \n",
       "        [[  101,  1045,  1049, ...,  2393,  1012,   102],\n",
       "         [    1,     1,     1, ...,     1,     1,     1],\n",
       "         [    0,     0,     0, ...,     0,     0,     0]]], dtype=int32)>,\n",
       " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
       " array([0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1,\n",
       "        0, 0, 0, 0, 0, 1, 0, 0, 0, 0], dtype=int32)>)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "all_batched = all_dataset.padded_batch(BATCH_SIZE,\n",
    "                                       padded_shapes=((3, None), ()),\n",
    "                                       padding_values=(0, 0))\n",
    "NB_BATCHES = math.ceil(len(sorted_all) / BATCH_SIZE)\n",
    "print('Total batches = ' + str(NB_BATCHES))\n",
    "NB_BATCHES_TEST = NB_BATCHES // 70\n",
    "print(NB_BATCHES_TEST)\n",
    "all_batched.shuffle(NB_BATCHES)\n",
    "test_dataset = all_batched.take(NB_BATCHES_TEST)\n",
    "train_dataset = all_batched.skip(NB_BATCHES_TEST)\n",
    "next(iter(train_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k82FVscqAgFY"
   },
   "source": [
    "# Building CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BWgX8JokAeJa"
   },
   "outputs": [],
   "source": [
    "class CNN(tf.keras.Model):\n",
    "\n",
    "  def __init__(self,\n",
    "               nb_filters=50,\n",
    "               FFN_units=512,\n",
    "               nb_classes=2,\n",
    "               dropout_rate=0.4,\n",
    "               training=False,\n",
    "               name='cnn'):\n",
    "    \n",
    "    super(CNN, self).__init__(name=name)\n",
    "\n",
    "    self.bert_layer = hub.KerasLayer(\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/1',\n",
    "        trainable=False\n",
    "    )\n",
    "    \n",
    "    self.conv1  = layers.Conv1D(filters=nb_filters,\n",
    "                                 kernel_size=2,\n",
    "                                 padding='valid',\n",
    "                                 activation='relu')\n",
    "    self.conv2  = layers.Conv1D(filters=nb_filters,\n",
    "                                 kernel_size=3,\n",
    "                                 padding='valid',\n",
    "                                 activation='relu')\n",
    "    self.conv3  = layers.Conv1D(filters=nb_filters,\n",
    "                                 kernel_size=4,\n",
    "                                 padding='valid',\n",
    "                                 activation='relu')\n",
    "    \n",
    "    self.pool = layers.GlobalMaxPool1D()\n",
    "\n",
    "    self.dense_1 = layers.Dense(units=FFN_units,\n",
    "                                activation='relu')\n",
    "    \n",
    "    self.dropout = layers.Dropout(rate = dropout_rate)\n",
    "\n",
    "    self.last_dense = layers.Dense(units=1,\n",
    "                                    activation='sigmoid')\n",
    "  \n",
    "  def embed_with_bert(self, all_tokens):\n",
    "    _, embs = self.bert_layer([all_tokens[:,0,:],\n",
    "                                all_tokens[:,1,:],\n",
    "                                all_tokens[:,2,:]])\n",
    "    return embs\n",
    "\n",
    "  def call(self,\n",
    "           inputs,\n",
    "           training):\n",
    "    x = self.embed_with_bert(inputs)\n",
    "    \n",
    "    \n",
    "    x_1 = self.conv1(x)\n",
    "    x_1 = self.pool(x_1)\n",
    "\n",
    "    x_2 = self.conv2(x)\n",
    "    x_2 = self.pool(x_2)\n",
    "\n",
    "\n",
    "    x_3 = self.conv3(x)\n",
    "    x_3 = self.pool(x_3)\n",
    "\n",
    "    merged = tf.concat([x_1, x_2, x_3], axis = 1)\n",
    "    merged = self.dense_1(merged)\n",
    "    merged = self.dropout(merged, training)\n",
    "    output = self.last_dense(merged)\n",
    "\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xp3zUrOeAe9t"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_BuAIGv5WwQR"
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iM9VleQ-WxHb"
   },
   "outputs": [],
   "source": [
    "VOCAB_SIZE = len(tokenizer.vocab)\n",
    "NB_FILTERS = 100\n",
    "FFN_UNITS = 256\n",
    "NB_CLASSES = 2\n",
    "\n",
    "DROPOUT_RATE = 0.4\n",
    "\n",
    "NB_EPOCH = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G3VAl8GdXI_m"
   },
   "outputs": [],
   "source": [
    "cnn = CNN(nb_filters=NB_FILTERS,\n",
    "          FFN_units=FFN_UNITS,\n",
    "          nb_classes=NB_CLASSES,\n",
    "          dropout_rate=DROPOUT_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m9pJ4JqtXhaL"
   },
   "outputs": [],
   "source": [
    "# if NB_CLASSES == 2:\n",
    "cnn.compile(loss='binary_crossentropy',\n",
    "            optimizer='adam',\n",
    "            metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UkYcF2ZQZ2cP",
    "outputId": "db1f9248-0725-4dd4-a386-2e72266a1495"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "154/154 [==============================] - 33s 214ms/step - loss: 0.1688 - accuracy: 0.9381\n",
      "Epoch 2/2\n",
      "106/154 [===================>..........] - ETA: 8s - loss: 0.1282 - accuracy: 0.9552"
     ]
    }
   ],
   "source": [
    "cnn.fit(\n",
    "        train_dataset,\n",
    "        epochs=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_RgXTQrEXYaq"
   },
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VE92CT-HYJQX",
    "outputId": "e81a6f77-8a2b-48c2-872e-2b3c4b9c8ef3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 2s 189ms/step - loss: 0.3293 - accuracy: 0.8750\n"
     ]
    }
   ],
   "source": [
    "results = cnn.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6hdneH_cXj7p"
   },
   "outputs": [],
   "source": [
    "def get_prediction(sentence):\n",
    "    tokens = encode_sentence(sentence)\n",
    "\n",
    "    input_ids = get_ids(tokens)\n",
    "    input_mask = get_mask(tokens)\n",
    "    segment_ids = get_segments(tokens)\n",
    "\n",
    "    inputs = tf.stack(\n",
    "        [tf.cast(input_ids, dtype=tf.int32),\n",
    "         tf.cast(input_mask, dtype=tf.int32),\n",
    "         tf.cast(segment_ids, dtype=tf.int32)],\n",
    "         axis=0)\n",
    "    inputs = tf.expand_dims(inputs, 0) # simulates a batch\n",
    "\n",
    "    output = cnn(inputs, training=False)\n",
    "\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EW11gw-BX_1X",
    "outputId": "2cd24023-3a7d-4ea4-b511-70dc799ca6b7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[0.80962]], dtype=float32)>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_prediction(\"I am stuck at abc road. I do not have any food to eat.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A_HzWV0vDs0E",
    "outputId": "0e7130bb-bfc3-4a7a-988b-f9918e4bebc0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[0.6016399]], dtype=float32)>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_prediction(\"I do not have any food to eat.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XUdsLHZFcCye",
    "outputId": "5dba11d4-3751-44d6-dced-0215a35854cb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[0.01664839]], dtype=float32)>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_prediction(\"I am really happy.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ddoF2ZSqcG-r",
    "outputId": "5542930d-0c44-4469-da09-9b4b17574439"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[0.2685689]], dtype=float32)>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_prediction(\"Help me.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2rdXwVpUcK1I",
    "outputId": "e50be7aa-87a5-4250-c708-5fa62a070734"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[0.8366738]], dtype=float32)>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_prediction(\"I donot have any food to eat, help me.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5s_HGnBXcOTH"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Tweet_Help_Classification_BERT.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
